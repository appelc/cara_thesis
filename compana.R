library(adehabitatHR)
library(googlesheets)
library(raster)
library(rgdal)
library(rgeos)
library(lattice)
library(rrcov)
library(ggplot2)
library(maptools)
library(dplyr)
library(sp)

######################
## 1. First, load porcupine location data & veg data
######################
gs_ls()
locs <- gs_title("Porc relocation data")
porc.vhf <- data.frame(gs_read(ss=locs, ws="Relocations", is.na(TRUE), range=cell_cols(c(1:8))))
colnames(porc.vhf) <- c("date", "id", "sess", "type", "time", "az", "utm_e", "utm_n")
porc.vhf <- subset(porc.vhf, type %in% c("V","V*","P","P*","L"))
porc.vhf$utm_e <- as.numeric(porc.vhf$utm_e)
porc.vhf$utm_n <- as.numeric(porc.vhf$utm_n)
## check date format before running line 51 or 52
porc.vhf$date <- as.Date(porc.vhf$date, "%m/%d/%Y") 
#porc.vhf$date <- as.Date(porc.vhf$date, origin = as.Date("1899-12-30"))

## Incorporate GPS data (1 random point per day)
porc.gps <- read.csv("daily.gps.csv") ## generated by 'gps_clean_IA.R'
porc.gps$type <- rep("gps", nrow(porc.gps))
porc.gps$az <- rep(NA, nrow(porc.gps))
porc.gps.df <- data.frame(porc.gps$Date, porc.gps$Animal.ID, porc.gps$Session, porc.gps$type,
                          porc.gps$Time, porc.gps$az, porc.gps$UTM.E, porc.gps$UTM.N)
colnames(porc.gps.df) <- colnames(porc.vhf)
porc.gps.df$date <- as.Date(porc.gps.df$date, "%m/%d/%Y")
porc.gps.df$id <- as.factor(porc.gps.df$id)

## combine VHF with GPS points
porc.locs <- rbind(porc.vhf, porc.gps.df)

## subset summer locations (before Nov 1 or after March 1) and winter (between Nov 1 and March 1)
sum.locs <- porc.locs[(porc.locs$date < "2015-11-01") | (porc.locs$date >= "2016-03-01"), ]
win.locs <- porc.locs[(porc.locs$date >= "2015-11-01") & (porc.locs$date < "2016-03-01"), ]

## can add seasons this way, but still need to subset because I don't want to remove ALL points from an 
## animal if it has <5 in only one season
#porc.locs$season[(porc.locs$date < "2015-11-01") | (porc.locs$date >= "2016-03-01")] <- 'summer'
#porc.locs$season[(porc.locs$date >= "2015-11-01") & (porc.locs$date < "2016-03-01")] <- 'winter'

## Keep only animals with >= 5 locations
n <- table(sum.locs$id)
sum.locs <- subset(sum.locs, id %in% names(n[n >= 5]), drop=TRUE)
sum.locs <- droplevels(sum.locs)

n <- table(win.locs$id)
win.locs <- subset(win.locs, id %in% names(n[n >= 5]), drop=TRUE)
win.locs <- droplevels(win.locs)

n <- table(porc.locs$id)
porc.locs <- subset(porc.locs, id %in% names(n[n >= 5]), drop=TRUE)
porc.locs <- droplevels(porc.locs)

## Load veg data
veg <- readOGR(dsn="shapefiles", layer="Veg categories CA", verbose=TRUE)
proj4string(veg) <- CRS("+proj=utm +zone=10 +datum=NAD83")
veg.ext <- readOGR(dsn="shapefiles", layer="Veg extent new", verbose=TRUE)
proj4string(veg.ext) <- proj4string(veg)

######################
## 2. Then, extract the UD from "adehabitatHR" package
###################### 

## Calculate grid & extent based on desired cell size (# meters on each side)
## For for each animal separately 

## Also calculate KUD based on summer points ONLY and winter points ONLY, but within 
## the grid of the extent for all of the points. Then clip to the 99% contour for all of 
## the points, as well as the veg layer extent.

ids <- unique(porc.locs$id)
kde.areas <- list()
kud.all <- list()
kern.i <- list()
outer_cont99 <- list()
contours99 <- list()
ud.third <- list()

for (i in ids){
        locs.i <- porc.locs[porc.locs$id == i,]
        locs.i$id_season <- rep(paste(i, "_all", sep = ""), nrow(locs.i))
        locs.sum.i <- sum.locs[sum.locs$id == i,]
        locs.sum.i$id_season <- rep(paste(i, "_sum", sep = ""), nrow(locs.sum.i))
        locs.win.i <- win.locs[win.locs$id == i,]
        locs.win.i$id_season <- rep(paste(i, "_win", sep = ""), nrow(locs.win.i))
        locs.all.i <- rbind(locs.i, locs.sum.i, locs.win.i)
        sp.i <- SpatialPointsDataFrame(data.frame(locs.all.i$utm_e, locs.all.i$utm_n),
                                       data=data.frame(locs.all.i$id_season),
                                       proj4string=CRS("+proj=utm +zone=10 +datum=NAD83"))
        c = 10   ## desired cell size (meters)
        fake.kern <- kernelUD(xy = sp.i, extent = 1)
        spdf <- raster(as(fake.kern[[1]], "SpatialPixelsDataFrame"))
        eas <- diff(range(spdf@extent[1:2]))
        nor <- diff(range(spdf@extent[3:4]))
        if(eas > nor){
          g <- (eas/c)
        } else {
          g <- (nor/c)
        }
        
        # calculate UD on all IDs ("all," "summer," "winter") with same4all = TRUE
        kern.i <- kernelUD(xy = sp.i, h = 60, grid = g, extent = 1, same4all = TRUE)
        kde.i <- kernel.area(kern.i, percent = c(50, 90, 95, 99), unin = "m", unout = "km2", standardize = FALSE)
        data.frame(kde.i, row.names = c("50", "90", "95", "99"))
        kde.areas[[i]] <- kde.i
        kud.all[[i]] <- kern.i
        
        # make 99% contours (full, summer, winter)
        cont99 <- list()
        for (j in 1:length(kern.i)){
          cont99.i <- getverticeshr.estUD(kern.i[[j]], percent = 99, unin = "m", unout = "km2", standardize = FALSE)
          cont99[[j]] <- cont99.i
        }
        
        ## merge all 3 contours to make a single contour based on the outermost areas
        outer_cont99.i <- raster::union(cont99[[1]], cont99[[2]])
        if ((length(cont99)) > 2) {
          outer_cont99.i <- raster::union(outer_cont99.i, cont99[[3]]) ## because not all have winter
        }
        
        outer_cont99.i <- gUnaryUnion(outer_cont99.i) ## dissolve polygons but this gets rid of @data
        outer_cont99.i@polygons[[1]]@ID <- 'homerange' ## so it will match when creating SPDF below
        
        ## create data to make it a SPDF (necessary for steps later)
        row_data <- data.frame('homerange', (outer_cont99.i@polygons[[1]]@Polygons[[1]]@area))
        rownames(row_data) <- rep('homerange', nrow(row_data))
        colnames(row_data) <- c('id', 'area')
        outer_cont99.i <- SpatialPolygonsDataFrame(outer_cont99.i, data = row_data)
        
        ## store contours (access as follows: contours[[i]][[j]] where i = ID and j = 1:all, 2:sum, 3:win)
        outer_cont99[[i]] <- outer_cont99.i ## store
        contours99[[i]] <- cont99
        
        # clip summer & winter UD grids to the 99% outer contour and veg extent for 3rd order analysis
        third.ud.i <- list()
        for (j in 1:length(kern.i)){
          clipped.ud.i <- (kern.i[[j]])[outer_cont99.i,] ## outer boundary from ALL contours, see above
          clipped.ud.i <- clipped.ud.i[veg.ext,]
          third.ud.i[[j]] <- clipped.ud.i
        }
        ud.third[[i]] <- third.ud.i
} 

######################
## 3. Extract UD heights
######################

ids <- unique(porc.locs$id)
heights.2 <- NULL

for (i in ids){
  heights.i <- NULL
  for(j in 1:length(ud.third[[i]])){
    ud.i <- ud.third[[i]][[j]]
    ud.height.i <- ud.i$ud
    coords.i <- ud.i@coords
    ht.coords.i <- data.frame((rep(i, length(ud.height.i))), rep(j, length(ud.height.i)), ud.height.i, coords.i)  
    colnames(ht.coords.i) <- c('id', 'season', 'height', 'x', 'y')
    heights.i <- rbind(heights.i, ht.coords.i)
  }
  heights.2 <- rbind(heights.2, heights.i)
}
 

######################
## 4. Assign values of covariates
######################

ids <- unique(porc.locs$id)

spdf.2 <- SpatialPointsDataFrame(data.frame(heights.2$x, heights.2$y),
                                 data=data.frame(heights.2$id, heights.2$season, heights.2$height),
                                 proj4string = CRS(proj4string(veg)))
spdf.2@data$veg <- over(spdf.2, veg)$Class_4
df.2 <- data.frame(spdf.2@data, spdf.2@coords)
colnames(df.2) <- c("id", "season", "ud", "veg", "x", "y")
df.2 <- df.2[!is.na(df.2$veg),] ## there were none anyway


######################
## 5. Create matrix of use values
######################

use_data <- list()

for (j in 1:3){
    uds <- df.2[df.2$season == j,]
    uds <- uds[,c(1, 3:4)]
    ids <- unique(uds$id)
    uds.season <- NULL
      for (i in ids){
          uds.id <- uds[uds$id == i,]
          uds.id <- aggregate(ud ~ veg, data = uds.id, FUN = sum)
          uds.id$prop_used <- uds.id$ud / sum(uds.id$ud)
          uds.id$id <- rep(i, nrow(uds.id))
          uds.id <- uds.id[,c(1, 3:4)]
          uds.season <- rbind(uds.season, uds.id)
      }
    use <- cast(uds.season, id ~ veg, value = 'prop_used')
    use_data[[j]] <- data.frame(use[,-1], row.names = use[,1])
    colnames(use_data[[j]]) <- gsub('[.]', ' ', colnames(use_data[[j]])) 
    use_data[[j]][is.na(use_data[[j]])] <- 0
}

## compana might not like 'NA' as opposed to 0.000001 or something
## OK to have different animals in each season?

######################
## 5. Create matrix of availability data
##    a. For the entire study area (2nd order)
######################

veg.area <- gArea(veg, byid = TRUE) ## calculates areas of all the polygons (in m^2?)
veg.df <- data.frame(veg$Class_4, veg.area)
colnames(veg.df) <- c('veg', 'area')

veg_sum <- aggregate(area ~ veg, data = veg.df, FUN = sum) ## sum areas by veg type
veg_prop <- veg_sum$area / sum(veg_sum$area)
veg_prop <- t(veg_prop)
colnames(veg_prop) <- veg_sum$veg 

## make list of matrices to match with avail
avail_list_2 <- list()
for (j in 1:3){
    avail_data_2 <- matrix(rep(veg_prop, nrow(use_data[[j]])), nrow = nrow(use_data[[j]]), byrow = TRUE)
    colnames(avail_data_2) <- colnames(veg_prop)
    avail_list_2[[j]] <- avail_data_2
}

######################
## 6. Try compositional analysis ('compana' in package adehabitatHS)
######################

## overall
compana(use_data[[1]], avail_list_2[[1]], test = 'randomisation', rnv = 0.000001, nrep = 500, alpha = 0.05)

## summer
compana(use_data[[2]], avail_list_2[[2]], test = 'randomisation', rnv = 0.000001, nrep = 500, alpha = 0.05)

## winter
compana(use_data[[3]], avail_list_2[[3]], test = 'randomisation', rnv = 0.000001, nrep = 500, alpha = 0.05)

## eigen visual analysis
(eis <- eisera(use_data[[2]], avail_list_2[[2]], scannf = FALSE))
barplot(eis$eig)
scatter(eis)

