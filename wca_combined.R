## Try weighted compositional analysis
## ala Millspaugh et al. 2006

# STEP 1: import data, incorporate GPS points, subset summer/winter (with >=5 locs per season),
#         and import veg data
# STEP 2: calculate UDs and 99% contours for each animal (overall/summer/winter) and create
#         overall outer contour boundary; clip UDs and store
# STEP 3: Create a list of tables with id, coord, and UD height for each animal
#         (at each each pixel)
# STEP 4: Assign values of covariates (veg categories) to cells
# STEP 5: Sum and divide the UD values per habitat type to get the "UD-weighted estimate of use"
# STEP 6: calculate availability data from veg polygons clipped to each animal's outer contour
# STEP 7-9: box plots, Wilk's lambda, etc.

#install.packages("ruf", repos="http://www.stat.ucla.edu/~handcock")
library(adehabitatHR)
library(googlesheets)
library(raster)
library(rgdal)
library(rgeos)
library(lattice)
library(rrcov)
library(ggplot2)
library(maptools)
library(dplyr)
library(sp)

######################
## 1. First, load porcupine location data & veg data
######################
gs_ls()
locs <- gs_title("Porc relocation data")
porc.locs <- data.frame(gs_read(ss=locs, ws="Relocations", is.na(TRUE), range=cell_cols(1:8)))
colnames(porc.locs) <- c("date", "id", "sess", "type", "time", "az", "utm_e", "utm_n")
porc.locs <- subset(porc.locs, type %in% c("V","V*","P","P*","L"))
porc.locs$utm_e <- as.numeric(porc.locs$utm_e)
porc.locs$utm_n <- as.numeric(porc.locs$utm_n)
## check date format before running line 51 or 52
porc.locs$date <- as.Date(porc.locs$date, "%m/%d/%Y") 
#porc.locs$date <- as.Date(porc.locs$date, origin = as.Date("1899-12-30"))

## Incorporate GPS data (1 random point per day)
gps.pts <- read.csv("daily.gps.csv") ## generated by 'gps_clean_IA.R'
gps.pts$type <- rep("gps", nrow(gps.pts))
gps.pts$az <- rep(NA, nrow(gps.pts))
gps.pts.df <- data.frame(gps.pts$Date, gps.pts$Animal.ID, gps.pts$Session, gps.pts$type,
                         gps.pts$Time, gps.pts$az, gps.pts$UTM.E, gps.pts$UTM.N)
colnames(gps.pts.df) <- colnames(porc.locs)
gps.pts.df$date <- as.Date(gps.pts.df$date, "%m/%d/%Y")
gps.pts.df$id <- as.factor(gps.pts.df$id)

## combine VHF with GPS points
porc.locs.all <- rbind(porc.locs, gps.pts.df)

## subset summer locations (before Nov 1 or after March 1) and winter (between Nov 1 and March 1)
sum.locs <- porc.locs.all[(porc.locs.all$date < "2015-11-01") | (porc.locs.all$date >= "2016-03-01"), ]
win.locs <- porc.locs.all[(porc.locs.all$date >= "2015-11-01") & (porc.locs.all$date < "2016-03-01"), ]

## Keep only animals with >= 5 locations
n <- table(sum.locs$id)
sum.locs <- subset(sum.locs, id %in% names(n[n >= 5]), drop=TRUE)
sum.locs <- droplevels(sum.locs)

n <- table(win.locs$id)
win.locs <- subset(win.locs, id %in% names(n[n >= 5]), drop=TRUE)
win.locs <- droplevels(win.locs)

n <- table(porc.locs.all$id)
porc.locs.all <- subset(porc.locs.all, id %in% names(n[n >= 5]), drop=TRUE)
porc.locs.all <- droplevels(porc.locs.all)

## Load veg data
veg <- readOGR(dsn="shapefiles", layer="Veg categories CA", verbose=TRUE)
proj4string(veg) <- CRS("+proj=utm +zone=10 +datum=NAD83")
veg.ext <- readOGR(dsn="shapefiles", layer="Veg extent new", verbose=TRUE)
proj4string(veg.ext) <- proj4string(veg)

######################
## 2. Then, extract the UD from "adehabitatHR" package
###################### 

## Calculate grid & extent based on desired cell size (# meters on each side)
## For for each animal separately 

## Also calculate KUD based on summer points ONLY and winter points ONLY, but within 
## the grid of the extent for all of the points. Then clip to the 99% contour for all of 
## the points, as well as the veg layer extent.

ids <- unique(porc.locs.all$id)
kde.areas <- list()
kud.all <- list()
kern.i <- list()
outer_cont99 <- list()
contours99 <- list()
ud.seasons <- list()

for (i in ids){
        locs.i <- porc.locs.all[porc.locs.all$id == i,]
        locs.i$id_season <- rep(paste(i, "_all", sep = ""), nrow(locs.i))
        locs.sum.i <- sum.locs[sum.locs$id == i,]
        locs.sum.i$id_season <- rep(paste(i, "_sum", sep = ""), nrow(locs.sum.i))
        locs.win.i <- win.locs[win.locs$id == i,]
        locs.win.i$id_season <- rep(paste(i, "_win", sep = ""), nrow(locs.win.i))
        locs.all.i <- rbind(locs.i, locs.sum.i, locs.win.i)
        sp.i <- SpatialPointsDataFrame(data.frame(locs.all.i$utm_e, locs.all.i$utm_n),
                                   data=data.frame(locs.all.i$id_season),
                                   proj4string=CRS("+proj=utm +zone=10 +datum=NAD83"))
        c = 10   ## desired cell size (meters)
        fake.kern <- kernelUD(xy = sp.i, extent = 1)
        spdf <- raster(as(fake.kern[[1]], "SpatialPixelsDataFrame"))
        eas <- diff(range(spdf@extent[1:2]))
        nor <- diff(range(spdf@extent[3:4]))
          if(eas > nor){
            g <- (eas/c)
          } else {
          g <- (nor/c)
          }
        
        # calculate UD on all IDs ("all," "summer," "winter") with same4all = TRUE
        kern.i <- kernelUD(xy = sp.i, h = 60, grid = g, extent = 1, same4all = TRUE)
        kde.i <- kernel.area(kern.i, percent = c(50, 90, 95, 99), unin = "m", unout = "km2", standardize = FALSE)
        data.frame(kde.i, row.names = c("50", "90", "95", "99"))
        kde.areas[[i]] <- kde.i
        kud.all[[i]] <- kern.i
        
        # make 99% contours (full, summer, winter)
        cont99 <- list()
        for (j in 1:length(kern.i)){
          cont99.i <- getverticeshr.estUD(kern.i[[j]], percent = 99, unin = "m", unout = "km2", standardize = FALSE)
          cont99[[j]] <- cont99.i
        }
        
        ## merge all 3 contours to make a single contour based on the outermost areas
        outer_cont99.i <- union(cont99[[1]], cont99[[2]])
          if ((length(cont99)) > 2) {
              outer_cont99.i <- union(outer_cont99.i, cont99[[3]]) ## because not all have winter
          }
        outer_cont99.i <- gUnaryUnion(outer_cont99.i) ## dissolve polygons but this gets rid of @data
        outer_cont99.i@polygons[[1]]@ID <- 'homerange' ## so it will match when creating SPDF below
        
        ## create data to make it a SPDF (necessary for steps later)
        row_data <- data.frame('homerange', (outer_cont99.i@polygons[[1]]@Polygons[[1]]@area))
        rownames(row_data) <- rep('homerange', nrow(row_data))
        colnames(row_data) <- c('id', 'area')
        outer_cont99.i <- SpatialPolygonsDataFrame(outer_cont99.i, data = row_data)
        
        ## store contours (access as follows: contours[[i]][[j]] where i = ID and j = 1:all, 2:sum, 3:win)
        outer_cont99[[i]] <- outer_cont99.i ## store
        contours99[[i]] <- cont99
      
        # clip summer UD grid to the 99% contour from ALL points (not just summer), and veg extent
        # do the same for winter
        sum.win.ud.i <- list()
        for (j in 1:length(kern.i)){
          clipped.ud.i <- (kern.i[[j]])[outer_cont99.i,] ## outer boundary from ALL contours, see above
          clipped.ud.i <- clipped.ud.i[veg.ext,]
          sum.win.ud.i[[j]] <- clipped.ud.i
        }
        ud.seasons[[i]] <- sum.win.ud.i
} 

## it's cool to look at a few here:
image(ud.seasons[[17]][[1]]) #first brackets are animal ID, second are season (1:all, 2:sum, 3:win)
plot(veg, add=TRUE)
plot(contours99[[17]][[1]], add=TRUE, border='black', lwd=2)
plot(contours99[[17]][[2]], add=TRUE, border='green', lwd=2) #summer
plot(contours99[[17]][[3]], add=TRUE, border='blue', lwd=2) #winter
plot(outer_cont99[[17]], add = TRUE, border = 'gray', lwd=2)

## combine this with porc_homerange.R file? or use this output for that analysis, at least
## output KDE areas
#write.csv(kde.areas, "csvs/kde_areas_w-gps_050916.csv")

######################
## 3. Then, create a list of tables with id, coord, and UD height for each porc
##    a. For UD height at each pixel
######################

ids <- unique(porc.locs.all$id)
heights.list <- list()

for(i in ids){
  heights.i <- list()
      for(j in 1:length(ud.seasons[[i]])){
        ud.i <- ud.seasons[[i]][[j]]
        ud.height.i <- ud.i$ud
        coords.i <- ud.i@coords
        ht.coords.i <- data.frame((rep(i, length(ud.height.i))), ud.height.i, coords.i)
        colnames(ht.coords.i) <- c("id", "height", "x", "y")
        heights.i[[j]] <- data.frame(ht.coords.i) 
      }
  heights.list[[i]] <- heights.i 
}

## wireframe plots! better function to get lat/lon or put it on a map?
wireframe(height ~ x * y, data = heights.list[[17]][[1]], drape=TRUE, main="15.17 overall UD height")
## nice! again, first brackets are animal ID, second are season (1:all, 2:sum, 3:win)

######################
## 4. Assign values of covariates (veg class, canopy height) to cells
######################

ids <- unique(porc.locs.all$id)
final.list <- list()

for (i in ids){
  final.i <- list()
        for(j in 1:length(heights.list[[i]])){
          ht.i <- heights.list[[i]][[j]]
          spdf.i <- SpatialPointsDataFrame(data.frame(ht.i$x, ht.i$y),
                                           data=data.frame(ht.i$id, ht.i$height),
                                           proj4string = CRS(proj4string(veg)))
          spdf.i@data$veg <- over(spdf.i, veg)$Class_2
          df.i <- data.frame(i, spdf.i@data$ht.i.height, spdf.i@coords, spdf.i@data$veg)
          colnames(df.i) <- c("id", "ud", "x", "y", "veg")
          df.i <- df.i[!is.na(df.i$veg),]
          final.i[[j]] <- df.i
        }
  final.list[[i]] <- final.i
}

## another cool figure:
plot(spdf.i)
plot(veg, add=TRUE)
#plot(contours99[[17]][[2]], add=TRUE, border="blue", lwd=2)
plot(outer_cont99[[17]], add = TRUE, border = 'blue', lwd = 2)
points(utm_n ~ utm_e, data=porc.locs.all[porc.locs.all$id == "16.18",], col="red", pch=16)
points(utm_n ~ utm_e, data=sum.locs[sum.locs$id == "16.18",], col="green", pch=16)
points(utm_n ~ utm_e, data=win.locs[win.locs$id == "16.18",], col="blue", pch=16)

######################
## 5. For weighted compositional analysis: 
## sum raw UD values by veg type and divide the summed UD values by the 
## total UD value of all patches to obtain a "UD-weighted estimate of use 
## for each habitat type for each individual animal" 
## - (Millspaugh et al. 2004 p. 391)
######################

## need to reclassify "0" use values because log(0) = -Inf, which means that veg category
## will be excluded. Eads et al. 2012 use 0.30, "the minimum value that reduced type I error
## rates in simulation studies (see Bingham et al. 2007)." I'll use 1e-10...
## ** do it for the sum or as the raw use? check out that paper and do error sensitivity **
## example: for 15.02, if I change raw UD=0 to 1e-10, the log_ud_weights are meadow = -12, 
## pasture = -12, shrub swale = -13, and wooded swale = -13.
## but when I change ud sum (after "aggregate") from 0 to 1e-10, the weights are all -18.4
## I'll do it the second way for now (change summed UD for each category to 1e-10 if it's 0)

## I don't think there end up being any -Inf in the summer data anyway

ids <- unique(porc.locs.all$id)
tables <- list()

for (i in ids){
  tables.i <- list()
      for (j in 1:length(final.list[[i]])){
          ud.i <- final.list[[i]][[j]]
          table.i <- aggregate(ud ~ veg, data = ud.i, FUN = sum) #if error, make sure there's no object 'sum' (rm(sum))
          table.i$ud[table.i$ud == 0] <- 1e-10 #do this here or before "aggregate"?
          table.i$ud_weight <- table.i$ud / sum(table.i$ud)
          table.i$log_ud_weight <- log(table.i$ud_weight)
          tables.i[[j]] <- table.i
      }
  tables[[i]] <- tables.i
}

######################
## 6. Now, calcluate "log-transformed availability data"
### CLIP POLYGONS Stolen from: https://philmikejones.wordpress.com/2015/09/01/clipping-polygons-in-r
### because "intersect" excludes some edge polygons and "gIntersection" doesn't retain polygon ids
######################

ids <- unique(porc.locs.all$id)
veg.99kdes <- list()
veg.tables <- list()

for (i in ids){
    cont99.i <- outer_cont99[[i]]
    clip.i <- gIntersection(cont99.i, veg, byid = T) #this is just a SpatialPolygons (no data)
    row.names(clip.i) <- gsub("homerange ", "", row.names(clip.i))    
    keep <- row.names(clip.i)
    clip.i <- spChFIDs(clip.i, keep) #changes feature IDs in the SP
    clip.data <- as.data.frame(veg@data[keep,]) #this is what we'll add as @data to the SPDF
    clip.spdf <- SpatialPolygonsDataFrame(clip.i, clip.data)  #this is fixed!
    clip.spdf <- clip.spdf[!is.na(clip.spdf@data$Class_2),] #get rid of NAs
    area.all <- gArea(clip.spdf, byid = TRUE) #units should be m^2
    veg.df.i <- data.frame(clip.spdf$Class_2, area.all)
    colnames(veg.df.i) <- c("veg", "area")
    veg.areas.i <- aggregate(area ~ veg, data=veg.df.i, FUN = sum)
    veg.areas.i$prop_area <- veg.areas.i$area / sum(veg.areas.i$area)
    veg.areas.i$log_avail <- log(veg.areas.i$prop_area)
    veg.99kdes[[i]] <- clip.spdf
    veg.tables[[i]] <- veg.areas.i
}

## good, no self-intersection errors!
## any missing polygons at edges?
plot(veg.99kdes[[17]]) #all look great!
plot(contours99[[17]][[1]], add = TRUE, border = 'black', lwd = 2)
plot(contours99[[17]][[2]], add = TRUE, border = 'green', lwd = 2)
plot(contours99[[17]][[3]], add = TRUE, border = 'blue', lwd = 2)
plot(outer_cont99[[17]], add = TRUE, border = 'red', lwd = 2, lty = 2)

######################
## 7. Subtract differences in log-transformed availability data from the
##    log-transformed use data for each animal and then test for overall
##    selection using Wilks' lambda
######################

## combine used and avail in the same table
## we have "tables" (list of used data) and "veg.tables" (list of avail data)

## the list final.tables will have 3 elements: [[1]]overall, [[2]]summer, and [[3]]winter

ids <- unique(porc.locs.all$id)
final.tables <- NULL

for (i in ids){
  final.table.i <- NULL
    for (j in 1:length(tables[[i]])){
      tables.j <- tables[[i]][[j]] ## proportional use based on season-specific UD
      veg.tables.j <- veg.tables[[i]] ## proportional avail. within OUTER contour
      tables.j$log_avail <- veg.tables.j$log_avail
      tables.j$id <- rep(i, nrow(tables.j))
      tables.j$sel <- tables.j$log_ud_weight - tables.j$log_avail
      tables.j$season <- rep(j, nrow(tables.j))
      final.df.j <- data.frame(tables.j$id, tables.j$season, tables.j$veg, 
                               tables.j$log_ud_weight, tables.j$log_avail, tables.j$sel)
      colnames(final.df.j) <- c('id', 'season', 'veg', 'log_ud_wt', 'log_avail', 'sel')
      final.table.i <- bind_rows(final.table.i, final.df.j)
    }
  final.tables <- bind_rows(final.tables, final.table.i)
}
## the 'unequal factor levels' error is OK

overall.sel <- final.tables[final.tables$season == 1,]
summer.sel <- final.tables[final.tables$season == 2,]
winter.sel <- final.tables[final.tables$season == 3,]

write.csv(overall.sel, 'csvs/overall_wt_comp_analysis_072416.csv')
write.csv(summer.sel, 'csvs/summer_wt_comp_analysis_072416.csv')
write.csv(winter.sel, 'csvs/winter_wt_comp_analysis_072416.csv')

######################
## 7. Make box plots
##    (need to do separately for summer/winter)
######################

par(mar=c(5, 9, 3, 3), xpd=FALSE)
boxplot(sel ~ veg, data = winter.sel, xaxt="n", las=2, horizontal=TRUE, outline=T)
axis(1)
title(xlab = "Differences in log ratio", line=3)
abline(v=0, lty = 1, col="red")

## **possible to get individual sel. values on the plot in and then the avg, instead of the box?

######################
## 8. Compute Wilk's lambda to test for overall selection
######################

## function "manova" or "Wilks.test"? the latter is in package "rrcov"
## "groups" are veg, and we are testing for differences between "log_ud_wt" and "log_avail"

groups <- as.factor(overall.sel$veg)
x <- as.matrix(overall.sel[,4:5])

## can do method "c" for mean and variance or "rank" for wilks lambda ranks
wilks.winter <- Wilks.test(x, grouping = groups, method="rank")
wilks.winter

######################
## 8. If use differes significantly from availability (p-value for Wilks lambda):
##    calculate the mean and st. dev. for the log-ratio differences,
##    and use these to rank each habitat type
## - Then, use t-test to assess difference between ranks and to determine where 
##   selection differed by habitat pairs (Millspaugh et al. 2006, p. 392)
######################

## calculate mean "sel" for each habitat type
veg_types <- unique(final.table$veg)
means_table <- NULL
for (j in veg_types) {
  veg.j <- final.table[final.table$veg == j,]
  mean.sel.j <- mean(veg.j$sel)
  sd.sel.j <- sd(veg.j$sel)
  se.sel.j <- (sd.sel.j)/sqrt(nrow(veg.j))
  table.j <- data.frame(j, mean.sel.j, sd.sel.j, se.sel.j)
  colnames(table.j) <- c("veg", "mean", "sdev", "se")  
  means_table <- rbind(means_table, table.j)
}

## rank veg types:
dodge <- position_dodge(width = 0.9)
limits <- aes(ymax = means_table$mean + means_table$se,
              ymin = means_table$mean - means_table$se)

p <- ggplot(data = means_table, aes(x = reorder(veg, mean), y = mean))
p + geom_bar(stat = "identity", position = dodge, fill = factor(veg_names_col$veg_colors)) +
  geom_errorbar(limits, position = dodge, width = 0.25) +
  theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(),
        axis.title.x=element_blank()) + ylab("Mean log-ratio differences (+/- SE)")

## where did the legend go?

## assign colors to each veg class for plotting
veg_names <- c("Beach", "Beachgrass dune", "Pasture", "Conifer forest", "Brackish marsh", 
               "Coastal scrub", "Meadow", "Freshwater marsh", "Wooded swale", "Shrub swale",
               "Fruit tree")
veg_colors <- c("khaki", "khaki3", "darkolivegreen3", "darkolivegreen4", "aquamarine", "khaki4",
                "yellow3", "cadetblue1", "aquamarine4", "darkseagreen3", "coral1")
veg_names_col <- data.frame(veg_names, veg_colors)

## t-tests to assess difference between ranks:


######################
######################
## cool figures but this is really messy (fix later):
ids <- unique(sum.locs$id)
for (i in ids){
  veg.i <- veg.99kdes[[i]][[2]]
  mypath <- file.path("figures", "kdes_with_veg", paste(i, "_veg_99kde", ".png", sep = ""))
  png(file=mypath)
  mytitle = paste("99% KDE ", i, sep = "")
  par(mar=c(2.1, 3.1, 3.1, 3.1), xpd=TRUE)
  plot(veg.i, main = mytitle)
  leg.txt <- sort(unique(veg$Class_2))
  leg.col <- c("khaki1", "khaki3", "aquamarine", "khaki4", "darkolivegreen4", "cadetblue1",
               "coral1", "yellow3", "darkolivegreen3", "darkseagreen3", "aquamarine4")
  legend("topright", inset=c(-0.3,0), legend = leg.txt, pch = 15, col = leg.col, cex=1.2)
  plot(veg.i[veg.i$Class_2 == "Beach",], add=TRUE, col="khaki1")
  plot(veg.i[veg.i$Class_2 == "Beachgrass dune",], add=TRUE, col="khaki3")
  plot(veg.i[veg.i$Class_2 == "Brackish marsh",], add=TRUE, col="aquamarine")
  plot(veg.i[veg.i$Class_2 == "Coastal scrub",], add=TRUE, col="khaki4")
  plot(veg.i[veg.i$Class_2 == "Conifer forest",], add=TRUE, col="darkolivegreen4")
  plot(veg.i[veg.i$Class_2 == "Freshwater marsh",], add=TRUE, col="cadetblue1")
  plot(veg.i[veg.i$Class_2 == "Fruit tree",], add=TRUE, col="coral1")
  plot(veg.i[veg.i$Class_2 == "Meadow",], add=TRUE, col="yellow3")
  plot(veg.i[veg.i$Class_2 == "Pasture",], add=TRUE, col="darkolivegreen3")
  plot(veg.i[veg.i$Class_2 == "Shrub swale",], add=TRUE, col="darkseagreen3")
  plot(veg.i[veg.i$Class_2 == "Wooded swale",], add=TRUE, col="aquamarine4")
  plot(porc.sp[porc.sp$porc.locs.all.id == i,], add=TRUE, pch=16, cex=1.5, col="black")
  plot(sum.sp[sum.sp$sum.locs.id == i,], add=TRUE, pch=16, cex=1.5, col="red")
  legend("bottomright", inset=c(-0.3,0), legend = c("Summer points", "Winter points"), pch=16, col=c("red", "black"), cex=1.2)
  scalebar(500, xy=click(), type='bar', divs=4, below = "meters")
  dev.off() 
}

## may need to run this again to be able to plot again:
#dev.off()

## quick and dirty home range plot:

ids.m <- c("15.03", "15.04", "15.06", "15.11", "15.14", "16.15", "16.18")
ids.f <- c("15.01", "15.02", "15.05", "15.07", "15.08", "15.09", "15.10", "15.12", "15.13", "16.16", "16.17")
ids.m <- c(3, 4, 6, 11, 14, 15, 17)
ids.f <- c(2, 5, 7, 8, 9, 10, 12, 13, 16)

plot(veg.ext, lwd = 2)
for (i in ids.m){
  plot(contour.list[[i]], add=TRUE, col='gray')
}

for (j in ids.f){
  plot(contour.list[[1]], add=TRUE, density = 20)
}

plot(veg.ext, lwd = 2)
legend("right", inset=c(0.1,0), legend = c("Female", "Male"), fill = c('gray', 'black'), 
       density = c(NA, 20), cex=1.2, title = "99% KDEs")
scalebar(1000, xy=click(), type='bar', divs=2, below = "m")

## females
plot(contour.list[[2]], add=TRUE, col='gray')
plot(contour.list[[12]], add=TRUE, col='gray')
plot(contour.list[[13]], add=TRUE, col='gray')
plot(contour.list[[16]], add=TRUE, col='gray')
plot(contour.list[[7]], add=TRUE, col='gray')
plot(contour.list[[9]], add=TRUE, col='gray')
plot(contour.list[[10]], add=TRUE, col='gray')
plot(contour.list[[8]], add=TRUE, col='gray')
plot(contour.list[[5]], add=TRUE, col='gray')
plot(contour.list[[1]], add=TRUE, col='gray')

## males
plot(contour.list[[3]], add=TRUE, density = 20)
#plot(contour.list[[4]], add=TRUE, density = 20)
plot(contour.list[[6]], add=TRUE, density = 20)
plot(contour.list[[11]], add=TRUE, density = 20)
plot(contour.list[[14]], add=TRUE, density = 20)
plot(contour.list[[15]], add=TRUE, density = 20)
plot(contour.list[[17]], add=TRUE, density = 20)

## make veg map
plot(veg)
plot(veg[veg$Class_4 == "beach",], add=TRUE, col="khaki1")
plot(veg[veg$Class_4 == "beachgrass dune",], add=TRUE, col="khaki3")
plot(veg[veg$Class_4 == "marsh",], add=TRUE, col="aquamarine")
plot(veg[veg$Class_4 == "coastal scrub",], add=TRUE, col="khaki4")
plot(veg[veg$Class_4 == "conifer forest",], add=TRUE, col="darkolivegreen4")
#plot(veg[veg$Class_2 == "freshwater marsh",], add=TRUE, col="cadetblue1")
plot(veg[veg$Class_4 == "fruit tree",], add=TRUE, col="coral1")
plot(veg[veg$Class_4 == "meadow",], add=TRUE, col="yellow3")
plot(veg[veg$Class_4 == "pasture",], add=TRUE, col="darkolivegreen3")
plot(veg[veg$Class_4 == "swale",], add=TRUE, col="darkseagreen3")
#plot(veg[veg$Class_2 == "Wooded swale",], add=TRUE, col="aquamarine4")

scalebar(1000, xy=click(), type='bar', divs=2, below = "m")

plot(porc.sp[porc.sp$porc.locs.all.id == i,], add=TRUE, pch=16, cex=1.5, col="black")
plot(sum.sp[sum.sp$sum.locs.id == i,], add=TRUE, pch=16, cex=1.5, col="red")